# PrezHelper IA

PrezHelper IA est un assistant intelligent pour l'aide √† l'utilisation de la plateforme Prezevent, bas√© sur l'IA g√©n√©rative et la recherche s√©mantique dans la documentation.

## Installation :
> T√©l√©charger Docker
docs.docker.com/engine/install/
```
git clone https://github.com/guillaume-desbarbieux/PrezHelper.git
cd PrezHelper
docker compose up
```
L'interface web Streamlit est disponible en local
(url indiqu√©e dans le terminal)

**Vous aurez besoin d'une Cl√© API d'OpenAI, √† renseigner sur l'interface pour ex√©cuter les requ√™tes.(https://platform.openai.com/)**

## Fonctionnalit√©s principales

- **Reformulation automatique** : Reformule la question utilisateur dans le style de la documentation technique pour am√©liorer la recherche.
- **Recherche s√©mantique (RAG)** : Trouve les documents les plus pertinents de la documentation Prezevent √† partir d'une question utilisateur, gr√¢ce √† des embeddings de phrases et un scoring mixte (titre/contenu).
- **G√©n√©ration de r√©ponse LLM** : G√©n√®re une r√©ponse synth√©tique √† partir des documents trouv√©s, ou de toute la documentation, en utilisant OpenAI GPT-4o.
- **Interface Streamlit** : Application web simple, avec sidebar de configuration et affichage des sources utilis√©es.
- **Gestion des images et descriptions** : Extraction, description automatique et regroupement des interfaces visuelles issues de la documentation.


## Choix technologiques

- **Python 3.10+**
- **Streamlit** : Interface utilisateur rapide et interactive.
- **SentenceTransformers** : Embeddings s√©mantiques pour la recherche documentaire (mod√®le par d√©faut : `msmarco-MiniLM-L6-cos-v5`).
- **scikit-learn** : Calcul de similarit√© cosinus.
- **OpenAI API** : G√©n√©ration de texte (GPT-4o).
- **Docker** : Conteneurisation pour reproductibilit√© et d√©ploiement facile.

## Pr√©paration et structuration du corpus

1. **Collecte** : R√©cup√©ration de la documentation Prezevent
    - scraping html automatique depuis help.prezevent.com
    - export des titres, paragraphes, listes, images et iframes.
2. **Mise en forme** :
    - mise en forme en dictionnaire : un objet par article.
    - Suppression des balises iframes
3. **Description image**
    - G√©n√©ration description technique des images via l'API OpenAI
    - Ajout de la description au sein de chaque article
4. **Formatage** :
    - Pour convenir au mieux aux attentes du LLM :
    - Chaque document est encapsul√© dans `[DOCUMENT] ... [/DOCUMENT]` avec les champs `Titre :`, `URL :`, `Contenu :`.
    - Les URL des images sont supprim√©es. Leur description se trouve dans le flux du contenu dans une balise `[Interface affich√©e: ...]`
   - Stockage dans un fichier JSON `corpus_list.json`

## Fonctionnement d√©taill√©

### 1. Reformulation de la question

- **But** : Adapter la question utilisateur au style de la documentation Prezevent pour maximiser la pertinence de la recherche documentaire.
- **Prompt syst√®me `prompt_system`** :
  > Tu es un assistant qui reformule des questions pos√©es en langage naturel par des utilisateurs, pour les adapter au style de la documentation de l‚Äôapplication Prezevent. La documentation utilise un style clair, direct, sous forme de questions techniques. Les titres des articles commencent souvent par 'Comment' et se concentrent sur une action pr√©cise, comme 'Comment exporter une liste de contacts ?' ou 'Comment cr√©er une campagne de mail ?'. Ta t√¢che est de reformuler les questions utilisateur dans ce style.
- **Mod√®le** : GPT-4o (OpenAI)
- **R√©sultat** : La question reformul√©e est utilis√©e pour la recherche documentaire.

### 2. Recherche documentaire (RAG)

- **But** : Trouver les documents les plus pertinents dans la base documentaire √† partir de la question reformul√©e.
- **Pipeline** :
  - Embedding de la question, des titres et contenus des documents avec SentenceTransformers.
  - Calcul d'un score mixte :
    - `score_mixte = alpha * score_titre + (1-alpha) * score_contenu`
  - S√©lection des documents selon :
    - `top_k` : nombre de documents √† retourner
    - `min_score` : score minimal de pertinence (cosinus)
    - `relative_margin` : √©cart autoris√© par rapport au meilleur score
    - `alpha` : poids du titre dans le score mixte
- **Int√©r√™t de chaque param√®tre** :
  - `top_k` : contr√¥le la quantit√© de contexte fourni au LLM
    Trop peu de contexte ne lui permettrait pas de trouver de r√©ponse.
    Trop de contexte risquerait de diluer les informations pertinentes et engendre un surco√ªt inutile.
  - `min_score` : filtre les documents peu pertinents
  - `relative_margin` : permet d'√©largir ou de restreindre la s√©lection autour du meilleur score
  - `alpha` : permet de donner plus d'importance au titre (souvent tr√®s informatif dans la doc Prezevent)

### 3. G√©n√©ration de la r√©ponse LLM

- **But** : G√©n√©rer une r√©ponse synth√©tique et sourc√©e √† partir des documents s√©lectionn√©s (ou de toute la documentation).
- **Pr√©paration du corpus pour le LLM**
    - Les documents pertinents sont concat√©n√©s et fournis en texte brut avec leurs balises sp√©cifiques :
    `[DOCUMENT] Titre :... , URL :... , Contenu : ... [Interface affich√©e: ...] ... [/DOCUMENT]`

- **Prompt syst√®me `prompt_system`** :
  > Tu es un assistant expert de Prezevent. Tu dois r√©pondre uniquement en utilisant les documents fournis dans chaque requ√™te. Ces documents peuvent inclure des descriptions d√©taill√©es d‚Äôinterfaces visuelles (captures d‚Äô√©cran) sous forme de texte. Ces descriptions remplacent l'image et doivent √™tre prises en compte pour comprendre les boutons, menus ou options affich√©s. Tu ne dois jamais mentionner d'images. Si aucune r√©ponse claire n‚Äôest pr√©sente dans les documents, r√©ponds simplement que tu ne sais pas. En fin de r√©ponse, indique toujours les articles utilis√©s sous la forme : üìÑ Source : [Titre de l‚Äôarticle](URL)

- **Prompt user `prompt_user`** :
  > Voici la question d'un utilisateur :\n`{question}`\n\nVoici les documents pertinents √† ta disposition :\nCertains passages d√©crivent l‚Äôinterface visuelle (ex : boutons, onglets, textes affich√©s). Ces descriptions textuelles remplacent les captures d‚Äô√©cran et sont √† interpr√©ter comme si tu voyais l‚Äô√©cran.\n\n`{corpus}`\n\nATTENTION : ne fais pas d'invention. Ne r√©ponds que si la r√©ponse est clairement pr√©sente.

- **Mod√®le** : GPT-4o (OpenAI)
- **Affichage** : La r√©ponse est affich√©e avec le co√ªt estim√© et le temps de g√©n√©ration.

### 4. Prefix Caching ###

    Pour r√©duire la latence et les co√ªts, l'API d'OpenAI g√®re le prefix caching. Pour que cela fonctionne, le prefixe de chaque requ√™te soit √™tre strictement identique.
    
    Les requ√™tes sont d√©j√† optimis√©s pour utiliser la capacit√© de prefix caching de l'API d'OpenAI : la premi√®re partie du prompt est statique, la seconde est dynamique :
    messages = [
                {"role": "system", "content": `prompt_system`},
                {"role": "user", "content": `prompt_user`}
                ]
    Cependant, ce prefix cache est temporaire, probablement li√© √† un cache LRU (least recently used) ou m√©moire locale GPU/session. Il est ind√©pendant de l‚Äôordre imm√©diat des appels : il peut retrouver un pr√©fixe d√©j√† vu 2, 3 ou plus appels avant, tant qu‚Äôil est encore en m√©moire (√† priori quelques secondes √† quelques minutes).  Ce cache n‚Äôest pas garanti (et n‚Äôest pas tra√ßable publiquement), mais est tr√®s souvent exploit√© si le prompt est fr√©quent.

## Pistes d'am√©lioration / TODO

- **Pipeline compl√®te** Mise en place du processus complet sans intervention utilisateur en utilisant les param√®tres les plus pertinents :
    Reformulation   ->  Recherche documentaire  ->  G√©n√©ration de la r√©ponse
- **Gestion des questions multiples** (D√©tection et d√©coupage en plusieurs requ√™tes via la phase de reformulation)
- **Affinage du scoring RAG** (poids dynamiques, prise en compte du contexte, nouvelle recherche documentaire avec ajustement des param√®tres avant g√©n√©ration si necessaire).
- **Ajout d'un mode conversationnel** (m√©moire de session, suivi de contexte).
- **Automatisation de la mise √† jour du corpus** (scraping r√©gulier, UI to text).
- **OpenAI Retrieval**
    https://platform.openai.com/docs/guides/retrieval

    OpenAI propose depuis peu de faire le RAG sur ses propres serveurs :
        - on fournit le contexte documentaire (text only)
        - la vectorisation et le stockage est fait sur les serveurs OpenAI
        - lorsqu'une requ√™te est envoy√©e, on fournit l'ID de la base vectorielle √† utiliser.
        - le serveur s'occupe de
            - la r√©-√©criture de la requ√™te
            - la recherche s√©mantique
            - renvoie les documents pertinents
        - Pour g√©n√©rer une r√©ponse, on retourne √† l'√©tape d√©crite plus haut (prompt + corpus + question)
    - Tarifs :
        - Facturation de la vectorisation initiale par token
        - Facturation du stockage (0,1/GB/jour) selon taille du corpus
        - Facturation classique pour chaque requ√™te de Retrieval par token
        !! Le retrieval est encore en version beta, les tarifs vont probablement √©voluer !!
    - Avantages :
        - Solution cl√© en main
        - Grande robustesse
        - R√©-indexation automatique sur upload
    - Inconv√©nients :
        - Pas de contr√¥le des param√®tres de retrieval (poids du titre, param√®tres dynamiques)
        - Stockage hors europe (√† priori pas de pb ici pour la doc)
        - couts suppl√©mentaires
        - La description d'images est √† g√©rer en amont dans tous les cas
